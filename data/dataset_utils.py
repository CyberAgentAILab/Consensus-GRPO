import os
import xml.etree.ElementTree as ET
from typing import List, Dict, Tuple, Optional, Any,Union
from datasets import Dataset, load_dataset, Image as HFImage
import json
import re
from PIL import Image
from io import BytesIO

def clean_summary_text(text: str) -> str:
    """Remove common English prefaces like 'Here is a concise summary...' and label prefixes.
    Keeps only the summary content, trimmed.
    """
    if not isinstance(text, str):
        return text
    unwanted_prefixes = [
        "Here is a concise summary of the article in 2-3 sentences:",
        "Here is a concise summary of the article:",
        "Here is a concise summary:",
        "Here is a summary:",
        "Summary:",
        "Summaries:",
        "TL;DR:",
    ]
    stripped = text.lstrip()
    for p in unwanted_prefixes:
        if stripped.lower().startswith(p.lower()):
            stripped = stripped[len(p):].lstrip(" \n:\t")
            break
    # Also strip leading quotation or bullet markers
    for ch in ['"', "'", "-", "â€¢", "*", "â€”", ":"]:
        if stripped.startswith(ch + " "):
            stripped = stripped[2:]
        elif stripped.startswith(ch):
            stripped = stripped[1:]
        stripped = stripped.lstrip()
    return stripped.strip()

def _infer_lang_and_direction_from_path(path: str) -> Tuple[Optional[str], bool]:
    """Infer non-English language code and direction from a dataset path.
    Returns (lang, reverse) where reverse=True means <non-en>â†’en (e.g., ja-en).
    """
    lowered = path.lower()
    for lang in ["ja", "zh", "de", "ru", "cs", "uk"]:
        if f"en-{lang}" in lowered or f"{lang}-en" in lowered:
            return lang, (f"{lang}-en" in lowered)
    return None, False

_IMAGE_CAPTION_LIMITS: Dict[str, Dict[str, int]] = {
    # Commonly used lightweight benchmarks for captioning experiments
    "nlphuji/flickr8k": {"train": 6000, "validation": 1000, "test": 1000},
    "nlphuji/flickr30k": {"train": 29000, "validation": 1000, "test": 1000},
    # Provide conservative defaults for larger corpora while keeping experiments tractable
    "huggingfacem4/coco": {"train": 12000, "validation": 2000, "test": 2000},
}


def _limit_image_caption_split(dataset: Dataset, dataset_name: str, split: str, is_train: bool) -> Dataset:
    """Apply size caps that mirror recent captioning recipes.

    The limits keep the default experiment lightweight (e.g. Flickr8k / Flickr30k)
    while still allowing larger datasets like COCO to be sampled without
    exhausting GPU memory when running GRPO.
    """

    if dataset is None:
        return dataset

    dataset_key = dataset_name.lower()
    split_key = (split or ("train" if is_train else "validation")).split("[")[0]
    limits = _IMAGE_CAPTION_LIMITS.get(dataset_key)

    if limits is None:
        # Fallback to a conservative global limit so that previously failing
        # COCO runs do not overwhelm the trainer.
        max_len = 12000 if is_train else 2000
    else:
        max_len = limits.get(split_key, limits.get("train" if is_train else "validation"))

    if max_len is None:
        return dataset

    orig_len = len(dataset)
    if orig_len > max_len:
        dataset = dataset.select(range(max_len))
        print(
            f"ðŸ“Š Limited {dataset_name} {split} split to {max_len} samples (from {orig_len})"
        )

    return dataset
def parse_xml_dataset(xml_path: str, reverse: bool = False, target_lang: Optional[str] = None) -> List[Dict]:
    tree = ET.parse(xml_path)
    root = tree.getroot()
    
    data = []
    
    for doc in root.findall(".//doc"):
        doc_id = doc.get("id", "")
        
        src_segments = {}
        ref_segments = {}

        # Determine parsing direction and target language
        inferred_lang, _ = _infer_lang_and_direction_from_path(xml_path)
        target = target_lang or inferred_lang

        if not reverse:
            # en -> target
            for src in doc.findall("./src[@lang='en']/p/seg"):
                seg_id = src.get("id", "")
                src_text = src.text.strip() if src.text else ""
                src_segments[seg_id] = src_text
            if target and doc.findall(f"./ref[@lang='{target}']/p/seg"):
                for ref in doc.findall(f"./ref[@lang='{target}']/p/seg"):
                    seg_id = ref.get("id", "")
                    ref_text = ref.text.strip() if ref.text else ""
                    ref_segments[seg_id] = ref_text
            else:
                # Fallback: try all supported targets
                for lang in ["ja", "de", "ru", "zh", "cs", "uk"]:
                    if doc.findall(f"./ref[@lang='{lang}']/p/seg"):
                        for ref in doc.findall(f"./ref[@lang='{lang}']/p/seg"):
                            seg_id = ref.get("id", "")
                            ref_text = ref.text.strip() if ref.text else ""
                            ref_segments[seg_id] = ref_text
                        break
        else:
            # target -> en (reverse)
            if target and doc.findall(f"./ref[@lang='{target}']/p/seg") and doc.findall("./src[@lang='en']/p/seg"):
                for ref in doc.findall(f"./ref[@lang='{target}']/p/seg"):
                    seg_id = ref.get("id", "")
                    ref_text = ref.text.strip() if ref.text else ""
                    src_segments[seg_id] = ref_text  # now source is the non-en text
                for src in doc.findall("./src[@lang='en']/p/seg"):
                    seg_id = src.get("id", "")
                    src_text = src.text.strip() if src.text else ""
                    ref_segments[seg_id] = src_text  # reference is English
            else:
                print(f"Reverse parsing failed to locate expected segments for doc {doc_id}")
                continue
        
        for seg_id, src_text in src_segments.items():
            if seg_id in ref_segments:
                data.append({
                    "doc_id": doc_id,
                    "seg_id": seg_id,
                    "source": src_text,
                    "reference": ref_segments[seg_id]
                })
    
    print(f"Extracted {len(data)} segment pairs from the dataset")
    return data

def _probe_jsonl_first_obj(path: str) -> Optional[Dict]:
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                if isinstance(obj, dict):
                    return obj
    except Exception:
        return None
    return None


def load_jsonl_datasets(train_paths: List[str], test_path: Optional[str] = None) -> Tuple[Dataset, Optional[Dataset]]:
    """Load generic JSONL datasets for mt/summary/math/mcq (without label requirement).

    Expected fields per line (flexible):
      - source / problem / prompt / question
      - reference / output / completion / answer / summary / translation
      - choices (optional, for MCQ prompts)
    """
    def read_jsonl(path: str) -> List[Dict]:
        items: List[Dict] = []
        with open(path, "r", encoding="utf-8") as f:
            for i, line in enumerate(f):
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                if not isinstance(obj, dict):
                    continue
                source = (
                    obj.get("source")
                    or obj.get("problem")
                    or obj.get("prompt")
                    or obj.get("question")
                    or obj.get("input")
                    or ""
                )
                reference = (
                    obj.get("reference")
                    or obj.get("output")
                    or obj.get("completion")
                    or obj.get("answer")
                    or obj.get("summary")
                    or obj.get("translation")
                    or obj.get("generated")
                    or ""
                )
                if not str(source).strip() or not str(reference).strip():
                    continue
                doc_id = str(obj.get("doc_id") or os.path.basename(path))
                seg_id = str(obj.get("seg_id") or i)
                record = {
                    "source": source,
                    "reference": reference,
                    "doc_id": doc_id,
                    "seg_id": seg_id,
                }
                if "problem" in obj:
                    record["problem"] = obj.get("problem")
                if "choices" in obj:
                    record["choices"] = obj.get("choices")
                if "label" in obj:
                    record["label"] = obj.get("label")
                items.append(record)
        return items

    train_items: List[Dict] = []
    for p in train_paths:
        if p.endswith(".jsonl"):
            train_items.extend(read_jsonl(p))
    train_dataset = Dataset.from_list(train_items) if train_items else Dataset.from_list([])

    test_dataset = None
    if test_path and test_path.endswith(".jsonl"):
        test_items = read_jsonl(test_path)
        test_dataset = Dataset.from_list(test_items)
    return train_dataset, test_dataset


def load_datasets(train_paths: List[str], test_path: Optional[str] = None, task: str = "mt") -> Tuple[Dataset, Optional[Dataset]]:
    # Check if we're loading image caption datasets
    if task == "image_caption":
        return load_image_caption_datasets(train_paths, test_path)
    # Check if we're loading math datasets
    if task == "math":
        return load_huggingface_datasets(train_paths, test_path, task="math")
    # Check if we're loading Hugging Face datasets for summarization
    if any(":" in path for path in train_paths):
        return load_huggingface_datasets(train_paths, test_path)
    # MCQ JSONL loader
    if any(path.endswith(".jsonl") for path in train_paths):
        if task == "mcq":
            probe_path = next((p for p in train_paths if p.endswith(".jsonl")), None)
            probe = _probe_jsonl_first_obj(probe_path) if probe_path else None
            if probe and ("label" in probe and "choices" in probe):
                return load_mcq_datasets(train_paths, test_path)
            return load_jsonl_datasets(train_paths, test_path)
        return load_jsonl_datasets(train_paths, test_path)
    
    # Original XML-based loading for machine translation
    train_data = []
    for path in train_paths:
        lang, reverse = _infer_lang_and_direction_from_path(path)
        train_data.extend(parse_xml_dataset(path, reverse=reverse, target_lang=lang))
    
    train_dataset = Dataset.from_list(train_data)
    
    test_dataset = None
    if test_path:
        lang, reverse = _infer_lang_and_direction_from_path(test_path)
        test_data = parse_xml_dataset(test_path, reverse=reverse, target_lang=lang)
        test_dataset = Dataset.from_list(test_data)
    
    return train_dataset, test_dataset

def load_huggingface_datasets(train_paths: List[str], test_path: Optional[str] = None, task: str = "summary") -> Tuple[Dataset, Optional[Dataset]]:
    """Load Hugging Face datasets for summarization and math tasks"""
    train_datasets = []
    
    for path in train_paths:
        if ":" in path:
            dataset_name, split = path.split(":")
            
            # For GSM8K, load with the main split (no config needed)
            if "gsm8k" in dataset_name.lower():
                dataset = load_dataset(dataset_name, "main", split=split)
            # For hendrycks_math, load all subjects and concatenate
            elif "hendrycks_math" in dataset_name.lower():
                math_subjects = ['algebra', 'counting_and_probability', 'geometry', 
                                'intermediate_algebra', 'number_theory', 'prealgebra', 'precalculus']
                subject_datasets = []
                for subject in math_subjects:
                    subject_dataset = load_dataset(dataset_name, subject, split=split)
                    subject_datasets.append(subject_dataset)
                from datasets import concatenate_datasets
                dataset = concatenate_datasets(subject_datasets)
                print(f"ðŸ“š Loaded {len(math_subjects)} subjects from {dataset_name}, total samples: {len(dataset)}")
            else:
                dataset = load_dataset(dataset_name, split=split)
            
            # Limit training dataset to first 6250 samples
            if len(dataset) > 6250:
                dataset = dataset.select(range(6250))
                print(f"ðŸ“Š Limited {dataset_name} training dataset to 6250 samples (from original size)")
            
            # Standardize column names for different datasets
            if dataset_name == "EdinburghNLP/xsum":
                dataset = dataset.rename_column("document", "source")
                dataset = dataset.rename_column("summary", "reference")
            elif dataset_name == "knkarthick/samsum":
                dataset = dataset.rename_column("dialogue", "source")
                dataset = dataset.rename_column("summary", "reference")
            elif "gsm8k" in dataset_name.lower():
                # GSM8K has 'question' and 'answer' columns
                # Rename to compatible format
                if "question" in dataset.column_names:
                    dataset = dataset.rename_column("question", "source")
                if "answer" in dataset.column_names:
                    dataset = dataset.rename_column("answer", "reference")
            elif "hendrycks_math" in dataset_name.lower():
                # hendrycks_math has 'problem' and 'solution' columns
                if "problem" in dataset.column_names:
                    dataset = dataset.rename_column("problem", "source")
                if "solution" in dataset.column_names:
                    dataset = dataset.rename_column("solution", "reference")
            
            # Add doc_id and seg_id for compatibility
            dataset = dataset.map(lambda example, idx: {
                **example, 
                "doc_id": f"{dataset_name}_{idx}", 
                "seg_id": str(idx)
            }, with_indices=True)
            
            train_datasets.append(dataset)
    
    # Concatenate all training datasets
    if len(train_datasets) == 1:
        train_dataset = train_datasets[0]
    else:
        from datasets import concatenate_datasets
        train_dataset = concatenate_datasets(train_datasets)
    
    # Load test dataset
    test_dataset = None
    if test_path and ":" in test_path:
        dataset_name, split = test_path.split(":")
        
        # For GSM8K, load with the main split
        if "gsm8k" in dataset_name.lower():
            test_dataset = load_dataset(dataset_name, "main", split=split)
        # For hendrycks_math, load all subjects and concatenate
        elif "hendrycks_math" in dataset_name.lower():
            math_subjects = ['algebra', 'counting_and_probability', 'geometry', 
                            'intermediate_algebra', 'number_theory', 'prealgebra', 'precalculus']
            subject_datasets = []
            for subject in math_subjects:
                subject_dataset = load_dataset(dataset_name, subject, split=split)
                subject_datasets.append(subject_dataset)
            from datasets import concatenate_datasets
            test_dataset = concatenate_datasets(subject_datasets)
            print(f"ðŸ“š Loaded {len(math_subjects)} subjects from {dataset_name}, total samples: {len(test_dataset)}")
        else:
            test_dataset = load_dataset(dataset_name, split=split)
        
        # Limit test dataset to first 500 samples
        if len(test_dataset) > 500:
            test_dataset = test_dataset.select(range(500))
            print(f"ðŸ“Š Limited {dataset_name} test dataset to 500 samples (from original size)")
        
        # Standardize column names
        if dataset_name == "EdinburghNLP/xsum":
            test_dataset = test_dataset.rename_column("document", "source")
            test_dataset = test_dataset.rename_column("summary", "reference")
        elif dataset_name == "knkarthick/samsum":
            test_dataset = test_dataset.rename_column("dialogue", "source")
            test_dataset = test_dataset.rename_column("summary", "reference")
        elif "gsm8k" in dataset_name.lower():
            # GSM8K has 'question' and 'answer' columns
            if "question" in test_dataset.column_names:
                test_dataset = test_dataset.rename_column("question", "source")
            if "answer" in test_dataset.column_names:
                test_dataset = test_dataset.rename_column("answer", "reference")
        elif "hendrycks_math" in dataset_name.lower():
            # hendrycks_math has 'problem' and 'solution' columns
            if "problem" in test_dataset.column_names:
                test_dataset = test_dataset.rename_column("problem", "source")
            if "solution" in test_dataset.column_names:
                test_dataset = test_dataset.rename_column("solution", "reference")
        
        # Add doc_id and seg_id for compatibility
        test_dataset = test_dataset.map(lambda example, idx: {
            **example, 
            "doc_id": f"{dataset_name}_{idx}", 
            "seg_id": str(idx)
        }, with_indices=True)
    
    return train_dataset, test_dataset

def load_mcq_datasets(train_paths: List[str], test_path: Optional[str] = None) -> Tuple[Dataset, Optional[Dataset]]:
    """Load local JSONL multiple-choice datasets produced under latest/grpo or grpo_small.

    Expects fields per line:
      - problem: str
      - choices: [str, str, str]
      - label: int (index of correct choice)
      - example_id (optional)
      - category (optional)

    Produces Dataset with columns:
      - problem, choices, label, source (alias of problem), reference (gold choice text), doc_id, seg_id
    """
    def read_jsonl(path: str) -> List[Dict]:
        items: List[Dict] = []
        with open(path, "r", encoding="utf-8") as f:
            for i, line in enumerate(f):
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                problem = obj.get("problem") or obj.get("source") or ""
                choices = obj.get("choices") or []
                label = obj.get("label")
                # normalize choices to list[str]
                norm_choices: List[str] = []
                for c in choices or []:
                    if isinstance(c, list):
                        norm_choices.append(str(c[0]) if c else "")
                    else:
                        norm_choices.append(str(c) if c is not None else "")
                if not norm_choices or label is None or not (0 <= int(label) < len(norm_choices)):
                    continue
                gold = norm_choices[int(label)]
                example_id = obj.get("example_id")
                doc_id = str(example_id) if example_id is not None else os.path.basename(path)
                seg_id = str(i)
                items.append({
                    "problem": problem,
                    "choices": norm_choices,
                    "label": int(label),
                    "source": problem,
                    "reference": gold,
                    "doc_id": doc_id,
                    "seg_id": seg_id,
                    "category": obj.get("category")
                })
        return items

    train_items: List[Dict] = []
    for p in train_paths:
        if p.endswith(".jsonl"):
            train_items.extend(read_jsonl(p))
    train_dataset = Dataset.from_list(train_items) if train_items else Dataset.from_list([])

    test_dataset = None
    if test_path and test_path.endswith(".jsonl"):
        test_items = read_jsonl(test_path)
        test_dataset = Dataset.from_list(test_items)
    return train_dataset, test_dataset

def load_image_caption_datasets(train_paths: List[str], test_path: Optional[str] = None) -> Tuple[Dataset, Optional[Dataset]]:
    """Load image caption datasets from Hugging Face (e.g., ``nlphuji/flickr8k``).

    The loader now supports multiple popular research benchmarks that follow the
    "image" + caption schema used in recent image-captioning papers. It
    automatically infers the correct image and caption columns from the dataset
    and normalizes them into a compact representation compatible with the rest
    of the training pipeline.

    Returns a ``Dataset`` with the following columns:

    - ``image``: PIL.Image or image data understood by ``datasets.Image``
    - ``reference``: caption text
    - ``doc_id`` / ``seg_id``: identifiers kept for compatibility with text tasks
    """

    def _infer_columns(dataset) -> Tuple[str, str]:
        candidate_image_cols = [
            "image",
            "images",
            "img",
            "image_data",
        ]
        candidate_caption_cols = [
            "reference",
            "caption",
            "captions",
            "sentences",
            "text",
            "sentence",
            "description",
            "annotations",
        ]

        image_col = next((c for c in candidate_image_cols if c in dataset.column_names), None)
        caption_col = next((c for c in candidate_caption_cols if c in dataset.column_names), None)

        # Flickr8k style: caption_0 ... caption_4
        if caption_col is None:
            pattern = re.compile(r"^caption(?:_\d+)?$", re.IGNORECASE)
            caption_like = [c for c in dataset.column_names if pattern.match(str(c))]
            if caption_like:
                caption_like.sort()
                caption_col = caption_like[0]

        if image_col is None or caption_col is None:
            raise ValueError(
                "Unable to infer image/caption columns. Please ensure the dataset "
                "has standard column names (e.g., 'image' and 'captions'). "
                f"Available columns: {dataset.column_names}"
            )

        return image_col, caption_col

    def _resolve_caption(raw_caption: Any) -> str:
        """Convert caption fields (str/list/dict) into a string."""
        if raw_caption is None:
            return ""
        if isinstance(raw_caption, str):
            return raw_caption.strip()
        if isinstance(raw_caption, dict):
            for key in ["raw", "text", "caption", "description", "value"]:
                value = raw_caption.get(key)
                if isinstance(value, str) and value.strip():
                    return value.strip()
            return ""
        if isinstance(raw_caption, list):
            for item in raw_caption:
                resolved = _resolve_caption(item)
                if resolved:
                    return resolved
            return ""
        return str(raw_caption).strip()

    def _standardize_dataset(dataset, dataset_name: str, split: str) -> Dataset:
        image_col, caption_col = _infer_columns(dataset)
        # Detect multiple caption columns (e.g., caption_0..caption_4)
        multi_caption_cols = sorted([
            c for c in dataset.column_names if str(c).lower().startswith("caption")
        ])

        # Optional image preprocessing controls via env vars
        # GRPO_IMAGE_MAX_SIDE: resize so that max(width, height) <= this (keep aspect). 0 or empty disables.
        # GRPO_IMAGE_FORCE_RGB: if "0" disables RGB conversion; otherwise force RGB.
        try:
            _max_side_env = os.getenv("GRPO_IMAGE_MAX_SIDE", "0") or "0"
            max_side = int(_max_side_env)
        except Exception:
            max_side = 0
        force_rgb = (os.getenv("GRPO_IMAGE_FORCE_RGB", "1") != "0")

        def _process(example: Dict[str, Any], idx: int) -> Dict[str, Any]:
            caption_text = ""
            if multi_caption_cols:
                for c in multi_caption_cols:
                    value = _resolve_caption(example.get(c))
                    if value:
                        caption_text = value
                        break
            if not caption_text:
                caption_text = _resolve_caption(example.get(caption_col))

            # Image retrieve and optional preprocessing
            img = example.get(image_col)
            # Ensure PIL.Image
            if img is not None and not isinstance(img, Image.Image):
                try:
                    # HF Image feature often yields PIL already; this is a safeguard
                    if isinstance(img, dict) and "bytes" in img:
                        img = Image.open(BytesIO(img["bytes"]))
                    else:
                        img = Image.open(img)
                except Exception:
                    pass
            # Convert to RGB if requested
            if isinstance(img, Image.Image) and force_rgb and img.mode != "RGB":
                try:
                    img = img.convert("RGB")
                except Exception:
                    pass
            # Resize keeping aspect ratio if max_side set
            if isinstance(img, Image.Image) and max_side and max_side > 0:
                try:
                    w, h = img.size
                    scale = min(1.0, float(max_side) / float(max(w, h)))
                    if scale < 1.0:
                        new_w = max(1, int(round(w * scale)))
                        new_h = max(1, int(round(h * scale)))
                        img = img.resize((new_w, new_h), Image.BICUBIC)
                except Exception:
                    pass

            # Build deterministic identifiers if the dataset does not provide one
            identifier_candidates = [
                example.get("doc_id"),
                example.get("id"),
                example.get("image_id"),
                example.get("uid"),
                example.get("sample_id"),
            ]
            doc_id = next((str(v) for v in identifier_candidates if v is not None and str(v).strip()), None)
            if doc_id is None:
                doc_id = f"{dataset_name}_{idx}"

            return {
                "image": img if isinstance(img, Image.Image) else example.get(image_col),
                "reference": caption_text,
                "doc_id": doc_id,
                "seg_id": str(idx),
            }

        kept_cols = {image_col}
        if multi_caption_cols:
            kept_cols.update(multi_caption_cols)
        else:
            kept_cols.add(caption_col)
        remove_columns = [col for col in dataset.column_names if col not in kept_cols]

        processed = dataset.map(
            _process,
            with_indices=True,
            remove_columns=remove_columns,
        )

        # Filter out empty captions that occasionally appear in raw datasets
        processed = processed.filter(lambda x: bool(x.get("reference")))

        # Preserve image features so downstream consumers receive PIL images.
        try:
            image_feature = dataset.features.get(image_col)
            if image_feature is not None:
                processed = processed.cast_column("image", image_feature)
            else:
                processed = processed.cast_column("image", HFImage())
        except Exception:
            pass

        processed = processed.with_format("python")

        return processed
    train_datasets = []
    
    for path in train_paths:
        if ":" not in path:
            continue
        dataset_name, split = path.split(":")
        dataset = load_dataset(dataset_name, split=split)

        dataset = _limit_image_caption_split(dataset, dataset_name, split, is_train=True)

        train_datasets.append(_standardize_dataset(dataset, dataset_name, split))

    if not train_datasets:
        raise ValueError("No valid training datasets were provided for image captioning.")

    if len(train_datasets) == 1:
        train_dataset = train_datasets[0]
    else:
        from datasets import concatenate_datasets
        train_dataset = concatenate_datasets(train_datasets)
    test_dataset = None
    if test_path and ":" in test_path:
        dataset_name, split = test_path.split(":")
        dataset = load_dataset(dataset_name, split=split)

        dataset = _limit_image_caption_split(dataset, dataset_name, split, is_train=False)

        test_dataset = _standardize_dataset(dataset, dataset_name, split)

    return train_dataset, test_dataset

def create_translation_prompt(source_text: str, args) -> str:
    if args.task != "mt":
        return ""

    ds = args.test_dataset.lower()

    # Reverse directions (non-en -> en)
    if "ja-en" in ds:
        return f"Translate the following Japanese text to English. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nJapanese text: {source_text}\n\nEnglish translation:"
    if "zh-en" in ds:
        return f"Translate the following Chinese text to English. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nChinese text: {source_text}\n\nEnglish translation:"
    if "uk-en" in ds:
        return f"Translate the following Ukrainian text to English. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nUkrainian text: {source_text}\n\nEnglish translation:"

    # Forward directions (en -> non-en)
    if "en-ja" in ds or "ja" in ds:
        return f"Translate the following English text to Japanese. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nEnglish text: {source_text}\n\nJapanese translation:"
    if "en-zh" in ds or "zh" in ds:
        return f"Translate the following English text to Chinese. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nEnglish text: {source_text}\n\nChinese translation:"
    if "en-de" in ds or "de" in ds:
        return f"Translate the following English text to German. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nEnglish text: {source_text}\n\nGerman translation:"
    if "en-ru" in ds or "ru" in ds:
        return f"Translate the following English text to Russian. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nEnglish text: {source_text}\n\nRussian translation:"
    if "en-cs" in ds or "cs" in ds:
        return f"Translate the following English text to Czech. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nEnglish text: {source_text}\n\nCzech translation:"
    if "en-uk" in ds or "uk" in ds:
        return f"Translate the following English text to Ukrainian. Do not include texts other than the translation. Translate the input with minimum loss of information.\n\nEnglish text: {source_text}\n\nUkrainian translation:"

def create_summarization_prompt(source_text: str, args) -> str:
    if source_text is None:
        source_text = ""
    
    # Ensure source_text is a string
    source_text = str(source_text)
    """Create a prompt for summarization tasks"""
    # Truncate source text to 3000 characters to prevent token overflow
    truncated_text = source_text[:2500] if len(source_text) > 2500 else source_text
    
    if "xsum" in args.train_datasets.lower():
        return f"Please write the summary only, without any preface or labels. Provide a concise summary of the following article focusing on the main point and key information.\n\nArticle: {truncated_text}\n\n"
    elif "samsum" in args.train_datasets.lower():
        return f"Please write the summary only, without any preface or labels. Provide a brief summary of the following conversation capturing the main points and key decisions.\n\nConversation: {truncated_text}\n\n"
    else:
        # Generic summarization prompt
        return f"Please write the summary only, without any preface or labels. Provide a concise summary of the following text.\n\nText: {truncated_text}\n\n"

def create_image_caption_prompt(args) -> Union[str, List[Dict]]:
    """Create a prompt for image caption tasks
    
    For VLMs, we return a conversational format that will be processed by the chat template.
    The image will be added separately in the prepare_dataset_for_grpo function.
    """
    # Return a conversational prompt that will be used with VLM chat template
    return [{"role": "user", "content": "Describe this image in a brief that captures all the key visual elements."}]

def create_mcq_prompt(problem: str, choices: List[str]) -> str:
    # Ensure strings
    problem = str(problem) if problem is not None else ""
    # Few-shot ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–æ™‚ã«æ§‹ç¯‰ï¼‰
    few_shot_header = (
        "ä»¥ä¸‹ã®ä¾‹ã«å¾“ã£ã¦å­¦ç¿’ã—ã¦ãã ã•ã„ï¼ˆä¾‹ã§ã¯è£œè¶³ã¯çœç•¥ã•ã‚Œã¦ã„ã¾ã™ï¼‰ã€‚\n\n"
    ) if _FEWSHOT_SECTION else ""
    return (
        "æ¬¡ã®å•é¡Œã«å¯¾ã—ã¦ç°¡æ½”ãªè£œè¶³èª¬æ˜Žã‚’ä»˜ã‘ã¦ã€ç­”ãˆã‚’æ—¥æœ¬èªžã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"{few_shot_header}{_FEWSHOT_SECTION}"
        f"å•é¡Œ: {problem}\n\n"
        "ç­”ãˆ:"
    )

def create_math_prompt(question: str) -> str:
    """Create a prompt for mathematical reasoning tasks (GSM8K)"""
    if question is None:
        question = ""
    question = str(question).strip()
    return question

# --------------------
# MCQ few-shot ä¾‹ã®æ•´å½¢
# --------------------

def _format_few_shot_section(examples: List[Dict]) -> str:
    if not examples:
        return ""
    lines: List[str] = []
    for i, ex in enumerate(examples, 1):
        # é¸æŠžè‚¢ã¯è¡¨ç¤ºã—ãªã„æ–¹é‡ã«åˆã‚ã›ã€å•é¡Œã¨ç­”ãˆã®ã¿
        prob = ex.get("problem", "")
        gold = ex.get("gold", "")
        lines.append(f"ã€ä¾‹{i}ã€‘\nå•é¡Œ: {prob}\nç­”ãˆ: {gold}\n")
    return "\n".join(lines).rstrip() + "\n\n"

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æ™‚ã« few-shot ã‚’å›ºå®šã§ç”¨æ„ï¼ˆlarge ã‹ã‚‰é¸å®šã€small ã«æœªåŽéŒ²ï¼‰
_FEWSHOT_EXAMPLES: List[Dict] = [
    {
        "example_id": "3836_5",
        "problem": "ç”ºå†…ä¼šã®ã‚¯ãƒªã‚¹ãƒžã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ã«25æ­³ã®å¥³æ€§ã¨48æ­³ã®å¥³ãŒå‚åŠ ã—ã‚ˆã†ã¨ã—ãŸãŒã€ä¸€äººã¯å‚åŠ ã‚’æ–­ã‚‰ã‚Œã¦ã—ã¾ã£ãŸã€‚\n\nèª°ãŒå‚åŠ ã‚’æ–­ã‚‰ã‚Œã¦ã—ã¾ã£ãŸã‹ï¼Ÿ",
        "gold": "ä¸æ˜Ž",
        "category": "Age",
    },
    {
        "example_id": "2703_1",
        "problem": "ä»Šæ—¥ã€è§’ã§2äººãŒäº¤é€šäº‹æ•…ã«é­ã£ãŸã€‚é‹è»¢æ‰‹ã®1äººã¯48æ­³ã§ã€ã‚‚ã†1äººã¯17æ­³ã ã£ãŸã€‚ ãã®17æ­³ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¯æ™‚é€Ÿ30ãƒžã‚¤ãƒ«ã®ã‚¾ãƒ¼ãƒ³ã‚’55ãƒžã‚¤ãƒ«ã§èµ°ã£ã¦ãŠã‚Šã€ä¿¡å·å¾…ã¡ã§å®Œå…¨ã«åœæ­¢ã—ãŸã¨ãã«ãã®48æ­³ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã«ã¶ã¤ã‹ã‚‰ãªã„ã‚ˆã†ã«åœæ­¢ã™ã‚‹ã“ã¨ãŒé–“ã«åˆã‚ãªã‹ã£ãŸã€‚\n\nèª°ãŒè²¬ä»»ã‚ã‚‹è¡Œå‹•ã‚’å–ã£ã¦ã„ãŸã®ã‹ï¼Ÿ",
        "gold": "48æ­³",
        "category": "Age",
    },
]
_FEWSHOT_SECTION: str = _format_few_shot_section(_FEWSHOT_EXAMPLES)

def prepare_dataset_for_grpo(dataset: Dataset, tokenizer, args) -> Dataset:

    def format_example(example):
        if args.task == "image_caption":
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": example.get("image")},
                        {"type": "text", "text": "Describe this image in a brief that captures all the key visual elements."}
                    ]
                }
            ]

            if hasattr(tokenizer, "apply_chat_template"):
                try:
                    prompt = tokenizer.apply_chat_template(
                        messages,
                        tokenize=False,
                        add_generation_prompt=True,
                    )
                except Exception:
                    prompt = "Describe this image in a brief that captures all the key visual elements."
            else:
                prompt = "Describe this image in a brief that captures all the key visual elements."

            return {
                "prompt": prompt,
                "messages": messages,
                "image": example.get("image"),
                "completion": example.get("reference", ""),
                "source": "",
                "ground_truth": example.get("reference", ""),
                "doc_id": example.get("doc_id", ""),
                "seg_id": example.get("seg_id", ""),
            }
        if args.task == "math":
            # For math tasks, use the special system prompt for reasoning
            question = example.get("question", example.get("source", ""))
            user_prompt = create_math_prompt(question)
            
            # Apply chat template with system message for math reasoning
            messages = [
                {"role": "system", "content": "Please reason step by step, and put your final answer within \\boxed{}."},
                {"role": "user", "content": user_prompt}
            ]
            
            formatted_prompt = tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True
            )
            
            return {
                "prompt": formatted_prompt,
                "completion": example.get("answer", example.get("reference", "")),
                "source": question,
                "ground_truth": example.get("answer", example.get("reference", "")),
                "doc_id": example.get("doc_id", ""),
                "seg_id": example.get("seg_id", ""),
            }
        if args.task == "summary":
            prompt = create_summarization_prompt(example["source"], args)
        elif args.task == "mcq":
            # Prefer problem/choices if available (from MCQ loader)
            problem = example.get("problem", example.get("source", ""))
            choices = example.get("choices", [])
            prompt = create_mcq_prompt(problem, choices)
        else:
            prompt = create_translation_prompt(example["source"], args)
        
        if args.model_name == "Qwen/Qwen3-8B":
            formatted_prompt = tokenizer.apply_chat_template(
            [{"role": "user", "content": prompt}],
            tokenize=False,
            add_generation_prompt=True,
            enable_thinking=False
        )
        else:
            formatted_prompt = tokenizer.apply_chat_template(
            [{"role": "user", "content": prompt}],
            tokenize=False,
            add_generation_prompt=True
        )
        
        return {
            "prompt": formatted_prompt,
            "completion": example["reference"],
            "source": example.get("source", example.get("problem", "")),
            "ground_truth": example["reference"],
            "doc_id": example.get("doc_id", ""),
            "seg_id": example.get("seg_id", ""),
            "choices": example.get("choices"),
            "label": example.get("label"),
        }
        
    formatted_dataset = dataset.map(format_example)
    
    return formatted_dataset

def split_dataset(dataset: Dataset, test_size: float = 0.1, seed: int = 42) -> Tuple[Dataset, Dataset]:

    if dataset is None or len(dataset) == 0:
        empty = Dataset.from_list([])
        return empty, empty

    # Prefer the built-in split to preserve feature metadata (e.g. images)
    try:
        split = dataset.train_test_split(test_size=test_size, seed=seed, shuffle=True)
        return split["train"], split["test"]
    except Exception:
        pass

    shuffled = dataset.shuffle(seed=seed)
    split_idx = int(len(shuffled) * (1 - test_size))

    if split_idx <= 0 or split_idx >= len(shuffled):
        return shuffled, Dataset.from_list([])

    train_dataset = shuffled.select(range(split_idx))
    val_dataset = shuffled.select(range(split_idx, len(shuffled)))

    return train_dataset, val_dataset